# Epic 1: Data Ingestion Pipeline

> **Role**: Scrum Master
> **Created**: 2025-12-04
> **Updated**: 2025-12-04
> **Epic Owner**: Developer
> **Priority**: P0 (Must Have)

---

## Epic Overview

### Goal
PDF íŒŒì¼ì„ Storm Parse APIë¡œ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ , ì²­í‚¹í•˜ì—¬ ë²¡í„° ì„ë² ë”©ì„ ìƒì„±í•œ í›„ Chroma DBì— ì €ì¥í•˜ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### Architecture

```mermaid
flowchart LR
    subgraph Input["ğŸ“ Input"]
        PDF[PDF Files]
    end

    subgraph Parsing["ğŸ“„ Storm Parse"]
        Upload[API Upload]
        Poll[Poll Result]
        MD[Structured MD]
    end

    subgraph Processing["âš™ï¸ Processing"]
        Meta[Metadata<br/>Extract]
        Chunk[Chunker<br/>800 tokens]
        Embed[Embedder<br/>OpenAI]
    end

    subgraph Storage["ğŸ’¾ Storage"]
        Chroma[(Chroma DB)]
        BM25[(BM25 Index)]
    end

    PDF --> Upload --> Poll --> MD
    MD --> Meta --> Chunk
    Chunk --> Embed --> Chroma
    Chunk --> BM25
```

### Success Criteria
- [ ] ë³´ìœ  PDF ì „ì²´ íŒŒì‹± ë° ì €ì¥ ì™„ë£Œ
- [ ] ëª¨ë“  ì²­í¬ì— ë©”íƒ€ë°ì´í„°(ì±…ëª…, ì±•í„°, í˜ì´ì§€) í¬í•¨
- [ ] Chroma DB + BM25 ì¸ë±ìŠ¤ ì •ìƒ êµ¬ì¶•
- [ ] ì²˜ë¦¬ ì‹œê°„ ë° ë¹„ìš© ë¦¬í¬íŠ¸ ìƒì„±

### Dependencies
- Storm Parse API Key
- OpenAI API Key
- PDF íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ

---

## Stories

### Story 1.1: í”„ë¡œì íŠ¸ ì´ˆê¸° ì„¤ì •

**As a** Developer
**I want** í”„ë¡œì íŠ¸ êµ¬ì¡°ì™€ ê°œë°œ í™˜ê²½ì„ ì„¤ì •
**So that** ì¼ê´€ëœ í™˜ê²½ì—ì„œ ê°œë°œì„ ì‹œì‘í•  ìˆ˜ ìˆë‹¤

#### Acceptance Criteria

```gherkin
Given ë¹ˆ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬
When ì´ˆê¸° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
Then pyproject.tomlì´ ìƒì„±ëœë‹¤
And í•„ìš”í•œ ë””ë ‰í† ë¦¬ êµ¬ì¡°ê°€ ìƒì„±ëœë‹¤
And .env.exampleì´ ìƒì„±ëœë‹¤
And ê°€ìƒí™˜ê²½ì— íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ëœë‹¤
```

#### Tasks
- [ ] `pyproject.toml` ì‘ì„± (Python 3.12+, ìµœì‹  íŒ¨í‚¤ì§€ ë²„ì „)
- [ ] ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± (`src/`, `data/`, `tests/`)
- [ ] `.env.example` ì‘ì„± (Storm API, OpenAI API í¬í•¨)
- [ ] `.gitignore` ì‘ì„±
- [ ] `Makefile` ê¸°ë³¸ ëª…ë ¹ì–´ ì‘ì„±
- [ ] `README.md` ì´ˆì•ˆ ì‘ì„±

#### Definition of Done
- `make install` ì‹¤í–‰ ì‹œ í™˜ê²½ êµ¬ì„± ì™„ë£Œ
- `python -c "import bookbrain"` ì„±ê³µ

---

### Story 1.2: Storm Parse API í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„

**As a** Developer
**I want** Storm Parse APIì™€ í†µì‹ í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
**So that** PDFë¥¼ êµ¬ì¡°í™”ëœ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤

#### Acceptance Criteria

```gherkin
Given PDF íŒŒì¼ ê²½ë¡œ
When StormParseClient.parse_pdf() í˜¸ì¶œ
Then PDFê°€ APIì— ì—…ë¡œë“œëœë‹¤
And jobIdê°€ ë°˜í™˜ëœë‹¤
And í´ë§ìœ¼ë¡œ COMPLETED ìƒíƒœê¹Œì§€ ëŒ€ê¸°í•œë‹¤
And êµ¬ì¡°í™”ëœ ë§ˆí¬ë‹¤ìš´ í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸ê°€ ë°˜í™˜ëœë‹¤
```

#### Tasks
- [ ] `StormParseClient` í´ë˜ìŠ¤ êµ¬í˜„
- [ ] `upload_pdf()` ë©”ì„œë“œ - multipart/form-data ì—…ë¡œë“œ
- [ ] `poll_result()` ë©”ì„œë“œ - ìƒíƒœ í´ë§ (with tenacity retry)
- [ ] `parse_pdf()` ë©”ì„œë“œ - í†µí•© íŒŒì´í”„ë¼ì¸
- [ ] `ParseResult`, `ParsePage` Pydantic ëª¨ë¸
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ (401, 403, timeout)
- [ ] ìœ ë‹› í…ŒìŠ¤íŠ¸ (ëª¨í‚¹)

#### API Endpoints

```python
# Upload
POST /api/v2/parse/by-file
Headers: Authorization: Bearer {token}
Body: multipart/form-data (file, language="ko")
Response: { "jobId": "...", "state": "REQUESTED" }

# Poll
GET /api/v2/parse/job/{jobId}
Response: { "state": "COMPLETED", "pages": [...] }
```

#### State Machine

```mermaid
stateDiagram-v2
    [*] --> REQUESTED: Upload PDF
    REQUESTED --> ACCEPTED: Processing started
    ACCEPTED --> PROCESSED: Parsing done
    PROCESSED --> COMPLETED: Ready
    COMPLETED --> [*]: Return pages

    REQUESTED --> ERROR: Failed
    ACCEPTED --> ERROR: Failed
    PROCESSED --> ERROR: Failed
```

#### Definition of Done
- í…ŒìŠ¤íŠ¸ PDF íŒŒì‹± ì„±ê³µ
- í˜ì´ì§€ë³„ content ë°˜í™˜ í™•ì¸
- ì—ëŸ¬ ì‹œ ì ì ˆí•œ ì˜ˆì™¸ ë°œìƒ

---

### Story 1.3: íŒŒì‹± ê²°ê³¼ ì²˜ë¦¬ê¸° êµ¬í˜„

**As a** Developer
**I want** Storm Parse ê²°ê³¼ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œ
**So that** ì²­í¬ì— ì¶œì²˜ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ ìˆë‹¤

#### Acceptance Criteria

```gherkin
Given Storm Parse API ê²°ê³¼ (pages ë¦¬ìŠ¤íŠ¸)
When ParseResultProcessor.process() í˜¸ì¶œ
Then ì±… ì œëª©ì´ ì¶”ì¶œëœë‹¤
And ì±•í„° ì •ë³´ê°€ ì¶”ì¶œëœë‹¤ (### íŒ¨í„´)
And í˜ì´ì§€ ë²ˆí˜¸ê°€ ë§¤í•‘ëœë‹¤
```

#### Tasks
- [ ] `ParseResultProcessor` í´ë˜ìŠ¤ êµ¬í˜„
- [ ] `extract_book_title()` - íŒŒì¼ëª… ë˜ëŠ” ì²« í˜ì´ì§€ì—ì„œ ì¶”ì¶œ
- [ ] `extract_chapters()` - ### íŒ¨í„´ìœ¼ë¡œ ì±•í„° êµ¬ë¶„
- [ ] `build_page_map()` - í˜ì´ì§€ ë²ˆí˜¸ â†’ ì½˜í…ì¸  ë§¤í•‘
- [ ] ìœ ë‹› í…ŒìŠ¤íŠ¸ (ì‹¤ì œ íŒŒì‹± ê²°ê³¼ ìƒ˜í”Œë¡œ)

#### Sample Parse Result

```python
# parse_result.txt í˜•ì‹ ë¶„ì„
{
    "pages": [
        {
            "pageNumber": 1,
            "content": "### ìë°” 8, 9, 10, 11 : ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ê°€?\n\nì´ ì¥ì˜ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤..."
        }
    ]
}

# ì¶”ì¶œí•  ë©”íƒ€ë°ì´í„°
metadata = {
    "book_title": "ëª¨ë˜ ìë°” ì¸ ì•¡ì…˜",
    "chapter": "1ì¥ - ìë°” 8, 9, 10, 11",
    "page_number": 37
}
```

#### Definition of Done
- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ë©”íƒ€ë°ì´í„° ì •í™•íˆ ì¶”ì¶œ
- ì±•í„° íŒ¨í„´ ì¸ì‹ë¥  > 90%

---

### Story 1.4: í…ìŠ¤íŠ¸ ì²­ì»¤ êµ¬í˜„

**As a** Developer
**I want** íŒŒì‹±ëœ í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰ì— ì í•©í•œ í¬ê¸°ë¡œ ë¶„í• 
**So that** ì •ë°€í•œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•˜ë‹¤

#### Acceptance Criteria

```gherkin
Given í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
When TextChunker.chunk() í˜¸ì¶œ
Then 800 í† í° í¬ê¸°ì˜ ì²­í¬ê°€ ìƒì„±ëœë‹¤
And 200 í† í°ì˜ ì˜¤ë²„ë©ì´ ì ìš©ëœë‹¤
And ì½”ë“œ ë¸”ë¡ì´ ì¤‘ê°„ì— ì˜ë¦¬ì§€ ì•ŠëŠ”ë‹¤
And ê° ì²­í¬ì— ì›ë³¸ í˜ì´ì§€ ì •ë³´ê°€ í¬í•¨ëœë‹¤
```

#### Tasks
- [ ] `TextChunker` í´ë˜ìŠ¤ êµ¬í˜„
- [ ] LangChain `RecursiveCharacterTextSplitter` í™œìš©
- [ ] tiktoken ê¸°ë°˜ í† í° ê³„ì‚°
- [ ] ì½”ë“œ ë¸”ë¡ ë³´ì¡´ ë¡œì§ (``` êµ¬ë¶„)
- [ ] ì²­í¬-í˜ì´ì§€ ë§¤í•‘ ë¡œì§
- [ ] `Chunk` Pydantic ëª¨ë¸
- [ ] ìœ ë‹› í…ŒìŠ¤íŠ¸ ì‘ì„±

#### Configuration

```python
CHUNK_CONFIG = {
    "chunk_size": 800,        # í† í°
    "chunk_overlap": 200,     # í† í°
    "separators": [
        "\n\n",               # ë‹¨ë½ êµ¬ë¶„
        "\n",                 # ì¤„ë°”ê¿ˆ
        "```",                # ì½”ë“œ ë¸”ë¡ (ë³´ì¡´ ì‹œë„)
        ". ",                 # ë¬¸ì¥ ë
        " ",                  # ë‹¨ì–´
    ],
    "length_function": lambda x: len(tiktoken.encoding_for_model("gpt-4").encode(x))
}
```

#### Definition of Done
- ì²­í¬ í¬ê¸°ê°€ 800 í† í° Â± 10% ë²”ìœ„
- ì½”ë“œ ë¸”ë¡ ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸ í†µê³¼
- ì˜¤ë²„ë©ìœ¼ë¡œ ë¬¸ë§¥ ì—°ê²° í™•ì¸

---

### Story 1.5: ì„ë² ë”© ìƒì„±ê¸° êµ¬í˜„

**As a** Developer
**I want** í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
**So that** ì‹œë§¨í‹± ê²€ìƒ‰ì´ ê°€ëŠ¥í•˜ë‹¤

#### Acceptance Criteria

```gherkin
Given í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸
When Embedder.embed_batch() í˜¸ì¶œ
Then OpenAI APIë¡œ ì„ë² ë”©ì´ ìƒì„±ëœë‹¤
And ë°°ì¹˜ ì²˜ë¦¬ë¡œ API í˜¸ì¶œì´ ìµœì í™”ëœë‹¤
And Rate limit ì—ëŸ¬ê°€ ì ì ˆíˆ í•¸ë“¤ë§ëœë‹¤
And ë¹„ìš©ì´ ê³„ì‚°ë˜ì–´ ë¡œê¹…ëœë‹¤
```

#### Tasks
- [ ] `Embedder` í´ë˜ìŠ¤ êµ¬í˜„ (async)
- [ ] OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
- [ ] ë°°ì¹˜ ì²˜ë¦¬ (100ê°œì”©)
- [ ] ì¬ì‹œë„ ë¡œì§ (tenacity)
- [ ] ë¹„ìš© ê³„ì‚° ë¡œì§
- [ ] `EmbeddedChunk` ëª¨ë¸
- [ ] ìœ ë‹› í…ŒìŠ¤íŠ¸ (ëª¨í‚¹)

#### Cost Estimation

```python
# text-embedding-3-small: $0.02 / 1M tokens
# ì˜ˆìƒ: 50ê¶Œ Ã— 200ì²­í¬ Ã— 800í† í° = 8M í† í° â‰ˆ $0.16
```

#### Definition of Done
- í…ŒìŠ¤íŠ¸ ì²­í¬ ì„ë² ë”© ì„±ê³µ
- 1536ì°¨ì› ë²¡í„° ìƒì„± í™•ì¸
- ë°°ì¹˜ ì²˜ë¦¬ ë™ì‘ í™•ì¸

---

### Story 1.6: Chroma ì €ì¥ì†Œ êµ¬í˜„

**As a** Developer
**I want** ì„ë² ë”©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ Chroma DBì— ì €ì¥
**So that** ë‚˜ì¤‘ì— ë²¡í„° ê²€ìƒ‰í•  ìˆ˜ ìˆë‹¤

#### Acceptance Criteria

```gherkin
Given ì„ë² ë”©ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
When ChromaStore.add() í˜¸ì¶œ
Then Chroma ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ì €ì¥ëœë‹¤
And ë©”íƒ€ë°ì´í„°ê°€ í•¨ê»˜ ì €ì¥ëœë‹¤
And ì¤‘ë³µ IDëŠ” ì—…ë°ì´íŠ¸ëœë‹¤
And ì €ì¥ ê±´ìˆ˜ê°€ ë¦¬í¬íŠ¸ëœë‹¤
```

#### Tasks
- [ ] `ChromaStore` í´ë˜ìŠ¤ êµ¬í˜„
- [ ] Chroma í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (HTTP ë˜ëŠ” persistent)
- [ ] ì»¬ë ‰ì…˜ ìƒì„±/ì¡°íšŒ ë¡œì§
- [ ] `add()` ë©”ì„œë“œ êµ¬í˜„
- [ ] ê¸°ì¡´ ë°ì´í„° ì‚­ì œ/ì¬ìƒì„± ì˜µì…˜
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±

#### Chroma Metadata

```python
# Chroma ë©”íƒ€ë°ì´í„° ì œí•œ: ë¬¸ìì—´, ìˆ«ì, ë¶ˆë¦¬ì–¸ë§Œ ê°€ëŠ¥
metadata = {
    "book_title": str,
    "book_file": str,
    "chapter": str,
    "page_start": int,
    "page_end": int,
    "chunk_index": int,
}
```

#### Definition of Done
- ë°ì´í„° ì €ì¥ í›„ ì¡°íšŒ ì„±ê³µ
- ë©”íƒ€ë°ì´í„° í•„í„°ë§ ë™ì‘ í™•ì¸
- ì»¬ë ‰ì…˜ ì‚­ì œ/ì¬ìƒì„± ë™ì‘ í™•ì¸

---

### Story 1.7: BM25 ì¸ë±ìŠ¤ êµ¬í˜„

**As a** Developer
**I want** ì²­í¬ í…ìŠ¤íŠ¸ë¡œ BM25 ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•
**So that** í‚¤ì›Œë“œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•˜ë‹¤

#### Acceptance Criteria

```gherkin
Given ëª¨ë“  ì²­í¬ í…ìŠ¤íŠ¸
When BM25Store.build_index() í˜¸ì¶œ
Then BM25 ì¸ë±ìŠ¤ê°€ ìƒì„±ëœë‹¤
And ì¸ë±ìŠ¤ê°€ íŒŒì¼ë¡œ ì €ì¥ëœë‹¤
And ë¡œë“œ ì‹œ ê²€ìƒ‰ì´ ë™ì‘í•œë‹¤
```

#### Tasks
- [ ] `BM25Store` í´ë˜ìŠ¤ êµ¬í˜„
- [ ] rank_bm25 ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©
- [ ] í† í¬ë‚˜ì´ì € ì„ íƒ (ê³µë°± ê¸°ë°˜)
- [ ] pickle ì €ì¥/ë¡œë“œ
- [ ] ì²­í¬ ID ë§¤í•‘ ìœ ì§€
- [ ] ìœ ë‹› í…ŒìŠ¤íŠ¸ ì‘ì„±

#### Implementation

```python
from rank_bm25 import BM25Okapi

class BM25Store:
    def __init__(self):
        self.bm25 = None
        self.chunk_ids = []

    def build_index(self, chunks: list[Chunk]):
        tokenized = [self._tokenize(c.text) for c in chunks]
        self.bm25 = BM25Okapi(tokenized)
        self.chunk_ids = [c.id for c in chunks]

    def _tokenize(self, text: str) -> list[str]:
        # ê°„ë‹¨í•œ ê³µë°± í† í¬ë‚˜ì´ì§• (í•œê¸€+ì˜ì–´ í˜¼í•©)
        return text.lower().split()

    def save(self, path: Path):
        with open(path, "wb") as f:
            pickle.dump({"bm25": self.bm25, "ids": self.chunk_ids}, f)

    def load(self, path: Path):
        with open(path, "rb") as f:
            data = pickle.load(f)
            self.bm25 = data["bm25"]
            self.chunk_ids = data["ids"]
```

#### Definition of Done
- ì¸ë±ìŠ¤ ë¹Œë“œ ì„±ê³µ
- í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜
- ì €ì¥/ë¡œë“œ ì‚¬ì´í´ ë™ì‘ í™•ì¸

---

### Story 1.8: íŒŒì‹± ê²°ê³¼ ìºì‹±

**As a** Developer
**I want** Storm Parse ê²°ê³¼ë¥¼ ë¡œì»¬ì— ìºì‹±
**So that** ì¬ì‹¤í–‰ ì‹œ API ë¹„ìš©ì„ ì ˆì•½í•  ìˆ˜ ìˆë‹¤

#### Acceptance Criteria

```gherkin
Given ì´ë¯¸ íŒŒì‹±ëœ PDF
When ë™ì¼ PDFë¡œ íŒŒì´í”„ë¼ì¸ ì¬ì‹¤í–‰
Then ìºì‹œëœ ê²°ê³¼ê°€ ì‚¬ìš©ëœë‹¤
And API í˜¸ì¶œì´ ë°œìƒí•˜ì§€ ì•ŠëŠ”ë‹¤
```

#### Tasks
- [ ] `ParseCache` í´ë˜ìŠ¤ êµ¬í˜„
- [ ] íŒŒì¼ í•´ì‹œ ê¸°ë°˜ ìºì‹œ í‚¤
- [ ] JSON íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥
- [ ] ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ ë¡œê¹…
- [ ] ìºì‹œ ë¬´íš¨í™” ì˜µì…˜ (--force-parse)

#### Cache Structure

```
data/parsed/
â”œâ”€â”€ {file_hash}_meta.json     # íŒŒì¼ ì •ë³´
â””â”€â”€ {file_hash}_pages.json    # íŒŒì‹± ê²°ê³¼
```

#### Definition of Done
- ìºì‹œ íˆíŠ¸ ì‹œ API í˜¸ì¶œ ì—†ìŒ
- --force-parse ì˜µì…˜ ë™ì‘

---

### Story 1.9: í†µí•© íŒŒì´í”„ë¼ì¸ êµ¬í˜„

**As a** Developer
**I want** PDF â†’ ë²¡í„° DB ì „ì²´ ê³¼ì •ì„ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì‹¤í–‰
**So that** ê°„í¸í•˜ê²Œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆë‹¤

#### Acceptance Criteria

```gherkin
Given PDF íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
When python scripts/ingest.py --pdf-dir ./data/pdfs ì‹¤í–‰
Then ëª¨ë“  PDFê°€ ì²˜ë¦¬ëœë‹¤
And Chroma DBì— ì €ì¥ëœë‹¤
And BM25 ì¸ë±ìŠ¤ê°€ ìƒì„±ëœë‹¤
And ì²˜ë¦¬ ë¦¬í¬íŠ¸ê°€ ì¶œë ¥ëœë‹¤
```

#### Tasks
- [ ] `IngestionPipeline` í´ë˜ìŠ¤ êµ¬í˜„
- [ ] CLI ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (`scripts/ingest.py`)
- [ ] Typer + Rich ê¸°ë°˜ CLI
- [ ] ì§„í–‰ë¥  í‘œì‹œ (rich.progress)
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ìŠ¤í‚µ ë¡œì§
- [ ] ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±

#### CLI Interface

```bash
# ì „ì²´ ìˆ˜ì§‘
python scripts/ingest.py --pdf-dir ./data/pdfs

# ë‹¨ì¼ íŒŒì¼
python scripts/ingest.py --pdf ./data/pdfs/modern_java.pdf

# ì¬ìˆ˜ì§‘ (ìºì‹œ ë¬´ì‹œ)
python scripts/ingest.py --pdf-dir ./data/pdfs --force-parse

# ë“œë¼ì´ëŸ° (ì €ì¥ ì•ˆ í•¨)
python scripts/ingest.py --pdf-dir ./data/pdfs --dry-run

# ì„ë² ë”©ë§Œ ì¬ìƒì„±
python scripts/ingest.py --pdf-dir ./data/pdfs --skip-parse
```

#### Report Example

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    Ingestion Report                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Total PDFs processed: 52                                    â•‘
â•‘  Total pages parsed: 12,345                                  â•‘
â•‘  Total chunks created: 10,234                                â•‘
â•‘  Total tokens embedded: 8,187,200                            â•‘
â•‘                                                              â•‘
â•‘  API Costs:                                                  â•‘
â•‘    Storm Parse: ~$XX.XX (52 documents)                       â•‘
â•‘    OpenAI Embedding: $0.16                                   â•‘
â•‘                                                              â•‘
â•‘  Processing time: 45m 12s                                    â•‘
â•‘                                                              â•‘
â•‘  Storage:                                                    â•‘
â•‘    Chroma collection: bookbrain (10,234 documents)           â•‘
â•‘    BM25 index: ./data/bm25_index.pkl (18MB)                  â•‘
â•‘                                                              â•‘
â•‘  Errors: 0                                                   â•‘
â•‘  Cache hits: 12 (skipped re-parsing)                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

#### Definition of Done
- í…ŒìŠ¤íŠ¸ PDF 3ê°œë¡œ E2E í…ŒìŠ¤íŠ¸ í†µê³¼
- ë¦¬í¬íŠ¸ ì •ìƒ ì¶œë ¥
- ì—ëŸ¬ ë°œìƒ ì‹œ ìŠ¤í‚µ í›„ ê³„ì† ì§„í–‰
- ìºì‹œ ë™ì‘ í™•ì¸

---

## Sprint Planning Suggestion

### Sprint 1 (Foundation)
- Story 1.1: í”„ë¡œì íŠ¸ ì´ˆê¸° ì„¤ì •
- Story 1.2: Storm Parse API í´ë¼ì´ì–¸íŠ¸

### Sprint 2 (Processing)
- Story 1.3: íŒŒì‹± ê²°ê³¼ ì²˜ë¦¬ê¸°
- Story 1.4: í…ìŠ¤íŠ¸ ì²­ì»¤
- Story 1.8: íŒŒì‹± ê²°ê³¼ ìºì‹±

### Sprint 3 (Storage & Integration)
- Story 1.5: ì„ë² ë”© ìƒì„±ê¸°
- Story 1.6: Chroma ì €ì¥ì†Œ
- Story 1.7: BM25 ì¸ë±ìŠ¤
- Story 1.9: í†µí•© íŒŒì´í”„ë¼ì¸

---

## Technical Considerations

### Async Architecture

```mermaid
flowchart TB
    subgraph Pipeline["Async Pipeline"]
        direction LR
        PDF1[PDF 1] --> Parse1[Parse]
        PDF2[PDF 2] --> Parse2[Parse]
        PDF3[PDF 3] --> Parse3[Parse]

        Parse1 --> Chunk1[Chunk]
        Parse2 --> Chunk2[Chunk]
        Parse3 --> Chunk3[Chunk]

        Chunk1 --> Embed[Embed<br/>Batch]
        Chunk2 --> Embed
        Chunk3 --> Embed

        Embed --> Store[Store]
    end
```

- Storm Parse: ë™ì‹œ ì—…ë¡œë“œ ê°€ëŠ¥ (rate limit í™•ì¸ í•„ìš”)
- OpenAI Embedding: ë°°ì¹˜ ì²˜ë¦¬ + async
- Chroma: ë°°ì¹˜ upsert

### Error Handling Strategy

| Error | Strategy |
|-------|----------|
| Storm Parse timeout | ìµœëŒ€ 10ë¶„ ëŒ€ê¸°, 3íšŒ ì¬ì‹œë„ |
| Storm Parse 500 | 5ë¶„ í›„ ì¬ì‹œë„, ìµœëŒ€ 3íšŒ |
| OpenAI rate limit | exponential backoff |
| Chroma connection | ì¬ì—°ê²° ì‹œë„ |

---

## Risks & Mitigations

| Risk | Mitigation |
|------|------------|
| Storm Parse API ë¹„ìš© ì´ˆê³¼ | ì‚¬ì „ ë¹„ìš© ê³„ì‚°, ìºì‹±ìœ¼ë¡œ ì¬í˜¸ì¶œ ë°©ì§€ |
| ëŒ€ìš©ëŸ‰ PDF ì²˜ë¦¬ ì‹œê°„ | ë¹„ë™ê¸° ì²˜ë¦¬, ì§„í–‰ë¥  í‘œì‹œ |
| íŒŒì‹± í’ˆì§ˆ ì´ìŠˆ | ìƒ˜í”Œ ê²€ì¦, ìˆ˜ë™ ë³´ì • ì˜µì…˜ |
| API ì¥ì•  | ì¬ì‹œë„ ë¡œì§, ë¶€ë¶„ ì €ì¥ |

